{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, hid_dim, Q):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(num_features, hid_dim, )\n",
    "        self.layer2 = nn.Linear(hid_dim, Q+1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.tanh(self.layer1(x))\n",
    "        return torch.tanh(self.layer2(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(784, 128, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 32\n",
    "pred = model(torch.randn(32, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1538, -0.2699,  0.0631,  0.1370,  0.1525,  0.3346],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.LongTensor(32, 6).random_(2)\n",
    "target[target == 0] = -1\n",
    "target[:, -1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1, -1, -1, -1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target == 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1538, -0.2699,  0.0631,  0.1370,  0.1525,  0.3346],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1, -1, -1, -1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_len = (target == 1).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1370,  0.1525,  0.3346, -0.0214,  0.0395,  0.2207, -0.3111, -0.2524,\n",
       "        -0.2001,  0.2694, -0.2033,  0.1533, -0.4755, -0.0811,  0.2288, -0.3581,\n",
       "         0.0348, -0.3792, -0.1841,  0.0346, -0.3769,  0.2206, -0.0462, -0.0744,\n",
       "        -0.2463, -0.1499,  0.1520,  0.5006,  0.0437,  0.0892,  0.3633, -0.0817,\n",
       "        -0.1748, -0.1177, -0.0820,  0.0428,  0.2778,  0.0552,  0.0068, -0.6666,\n",
       "         0.1336, -0.3399,  0.1519, -0.1544, -0.4578, -0.1637, -0.2238, -0.0281,\n",
       "         0.0509, -0.2604, -0.0480,  0.0253, -0.3028,  0.0163, -0.3523,  0.1998,\n",
       "         0.3421,  0.2768, -0.1208,  0.0967, -0.1212, -0.1370, -0.1003, -0.1263,\n",
       "        -0.2182, -0.1465, -0.1741, -0.0500, -0.2250,  0.0793,  0.0221,  0.0800,\n",
       "        -0.3202,  0.4363, -0.3181,  0.1527,  0.1289, -0.0779, -0.4038, -0.1619,\n",
       "        -0.1157,  0.0648, -0.2893, -0.2688, -0.0756, -0.0534,  0.2256,  0.1190,\n",
       "         0.3872,  0.2172, -0.0878,  0.1916, -0.0011, -0.1405, -0.4153,  0.3311,\n",
       "        -0.6489, -0.0318,  0.2034,  0.1297, -0.3336,  0.1084,  0.4505,  0.1104,\n",
       "         0.3420,  0.1563, -0.2272, -0.0385, -0.1472], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[target != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1538, -0.2699,  0.0631, -0.3415, -0.0589,  0.1118, -0.5181,  0.0440,\n",
       "         0.0274,  0.0588,  0.1181, -0.2815,  0.3124,  0.2901, -0.1496,  0.1104,\n",
       "         0.1713, -0.1747, -0.5449, -0.5452, -0.6001,  0.2767, -0.0565,  0.0175,\n",
       "        -0.0140, -0.5178, -0.2032,  0.6539,  0.0596,  0.3487,  0.2369, -0.1497,\n",
       "         0.0939, -0.0731, -0.0132,  0.1805,  0.0221, -0.2144,  0.3083,  0.0999,\n",
       "         0.1902,  0.2467,  0.1114,  0.1179,  0.3368,  0.0907, -0.0222, -0.0408,\n",
       "         0.5809, -0.0505,  0.0016, -0.0960, -0.0569,  0.1871,  0.0078,  0.0211,\n",
       "         0.0356, -0.3493, -0.1166, -0.1218,  0.0360,  0.5139, -0.2095,  0.2201,\n",
       "         0.4413, -0.1289,  0.1475, -0.1728,  0.0198, -0.2126,  0.1927,  0.2449,\n",
       "        -0.1707, -0.1230,  0.4882,  0.2381, -0.0067, -0.2007,  0.0294, -0.1386,\n",
       "        -0.1191, -0.2374, -0.4394], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[target == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 4, 2, 3, 2, 1, 2, 2, 4, 2, 2, 4, 4, 2, 2, 1, 2, 4, 2, 0, 4, 3, 4,\n",
       "        3, 2, 2, 3, 4, 1, 3, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1538, -0.2699,  0.0631, -0.3415, -0.0589,  0.1118, -0.5181,  0.0440,\n",
       "         0.0274,  0.0588,  0.1181, -0.2815,  0.3124,  0.2901, -0.1496,  0.1104,\n",
       "         0.1713, -0.1747, -0.5449, -0.5452, -0.6001,  0.2767, -0.0565,  0.0175,\n",
       "        -0.0140, -0.5178, -0.2032,  0.6539,  0.0596,  0.3487,  0.2369, -0.1497,\n",
       "         0.0939, -0.0731, -0.0132,  0.1805,  0.0221, -0.2144,  0.3083,  0.0999,\n",
       "         0.1902,  0.2467,  0.1114,  0.1179,  0.3368,  0.0907, -0.0222, -0.0408,\n",
       "         0.5809, -0.0505,  0.0016, -0.0960, -0.0569,  0.1871,  0.0078,  0.0211,\n",
       "         0.0356, -0.3493, -0.1166, -0.1218,  0.0360,  0.5139, -0.2095,  0.2201,\n",
       "         0.4413, -0.1289,  0.1475, -0.1728,  0.0198, -0.2126,  0.1927,  0.2449,\n",
       "        -0.1707, -0.1230,  0.4882,  0.2381, -0.0067, -0.2007,  0.0294, -0.1386,\n",
       "        -0.1191, -0.2374, -0.4394], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPMLLLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(_Loss, self).__init__()\n",
    "        if size_average is not None or reduce is not None:\n",
    "            self.reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
    "        else:\n",
    "            self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tkde06a.pdf\n",
    "        # input's shape is (bsz, Q)\n",
    "        # target's shape is (bsz, Q)\n",
    "        # target's unique value is in [-1, 1]\n",
    "        Y = (target == 1)\n",
    "        Y_bar = (target != 1)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
