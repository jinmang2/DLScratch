{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "# from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 계층적인 폴더 구조를 갖고 있는 데이터셋을 불러올때 사용 : 폴더 이름 = 클래스 명\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchvision.models import resnet152\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "    \n",
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another\n",
    "dataset = ImageFolder('../data/Images')\n",
    "\n",
    "test_pct = 0.2\n",
    "test_size = int(len(dataset)*test_pct)\n",
    "dataset_size = len(dataset) - test_size\n",
    "\n",
    "val_pct = 0.1\n",
    "val_size = int(dataset_size*val_pct)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "train, val, test = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# custom Dataset\n",
    "class DogData(Dataset) :\n",
    "    def __init__(self, ds, transform = None) :\n",
    "        self.ds = ds\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        img, label = self.ds[idx]\n",
    "        if self.transform :\n",
    "            img = self.transform(img)\n",
    "            return img, label\n",
    "\n",
    "        \n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225]) \n",
    "                                      ])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "                                     transforms.Resize(255), \n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                                     transforms.Resize(255), \n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "train = DogData(train, train_transforms)\n",
    "val = DogData(val, val_transforms)\n",
    "test = DogData(test, test_transforms)\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(train, batch_size=batch_size, \n",
    "                                              num_workers=num_workers, shuffle=True)\n",
    "valLoader = torch.utils.data.DataLoader(val, batch_size=batch_size, \n",
    "                                            num_workers=num_workers, shuffle=False)\n",
    "testLoader = torch.utils.data.DataLoader(test, batch_size=batch_size,\n",
    "                                             num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet152(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    \n",
    "    def __init__(self, resnet, n_classes, freeze=True):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet\n",
    "        if freeze:\n",
    "            for param in resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "        n_inputs = self.resnet.fc.out_features # 1000\n",
    "        # 학습시킬 파라미터\n",
    "        self.fc1 = nn.Linear(n_inputs, 1024)\n",
    "        self.fc2 = nn.Linear(1024, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return torch.relu(self.fc2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate를 단계적으로 줄여주는 방법\n",
    "# epoch 100 -> lr/10, 150 -> lr/10\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    if epoch >= 150:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# backpropagation method\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
    "# hyper-parameters\n",
    "num_batches = len(trainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e349db271548649c19afe1c470a0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001/200 | step: 116/232 | trn loss: 003.4952 | val loss: 001.7386 | acc: 64.70\n",
      "epoch: 001/200 | step: 232/232 | trn loss: 002.3490 | val loss: 001.4075 | acc: 70.78\n",
      "epoch: 002/200 | step: 116/232 | trn loss: 002.1740 | val loss: 001.2127 | acc: 74.18\n",
      "epoch: 002/200 | step: 232/232 | trn loss: 002.0295 | val loss: 001.2013 | acc: 73.88\n",
      "epoch: 003/200 | step: 116/232 | trn loss: 001.8850 | val loss: 001.0433 | acc: 76.37\n",
      "epoch: 003/200 | step: 232/232 | trn loss: 001.8532 | val loss: 001.0472 | acc: 75.88\n"
     ]
    }
   ],
   "source": [
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    adjust_learning_rate(optimizer,epoch)\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(trainLoader):\n",
    "        x, label = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        model_output = model(x)\n",
    "        loss = criterion(model_output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        trn_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % (num_batches // 2) == 0: # every 100 mini-batches\n",
    "            with torch.no_grad(): # very very very very important!!!\n",
    "                val_loss = 0.0\n",
    "                corr_num = 0\n",
    "                total_num = 0\n",
    "                for j, val in enumerate(valLoader):\n",
    "                    val_x, val_label = val[0].to(device), val[1].to(device)\n",
    "                    val_output = model(val_x)\n",
    "                    v_loss = criterion(val_output, val_label)\n",
    "                    val_loss += v_loss\n",
    "                    \n",
    "                    model_label = val_output.argmax(dim=1)\n",
    "                    corr = torch.eq(val_label, model_label).sum()\n",
    "                    corr_num += corr.item()\n",
    "                    total_num += val_label.size(0)\n",
    "            \n",
    "                print(f\"epoch: {epoch+1:03d}/{num_epochs} | \"\n",
    "                      f\"step: {i+1:03d}/{num_batches} | \"\n",
    "                      f\"trn loss: {trn_loss/100:08.4f} \"\n",
    "                      f\"| val loss: {val_loss/len(valLoader):08.4f} \"\n",
    "                      f\"| acc: {(corr_num/total_num)*100:.2f}\")           \n",
    "            \n",
    "            trn_loss_list.append(trn_loss/100)\n",
    "            val_loss_list.append(val_loss/len(valLoader))\n",
    "            trn_loss = 0.0\n",
    "\n",
    "print(\"training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "PATH = \"model.pt\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "print(\"model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test acc\n",
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    for j, val in enumerate(testLoader):\n",
    "        val_x, val_label = val\n",
    "        val_x = val_x.to(device)\n",
    "        val_label =val_label.to(device)\n",
    "        val_output = model(val_x)\n",
    "        model_label = val_output.argmax(dim=1)\n",
    "        corr = val_label[val_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += val_label.size(0)\n",
    "\n",
    "print(\"test_acc: {:.2f}\".format(corr_num / total_num * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(trn_loss_list, label=\"train_loss\")\n",
    "plt.legend()\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
