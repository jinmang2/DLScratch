{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import (\n",
    "    Dataset, RandomSampler, DataLoader)\n",
    "\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist(flatten=True, normalize=True, one_hot_label=False)\n",
    "\n",
    "x_train, y_train, x_test, y_test = (\n",
    "    torch.Tensor(d) for d in (x_train, y_train, x_test, y_test)\n",
    ")\n",
    "\n",
    "y_train = y_train.long()\n",
    "y_test = y_test.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MnistDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = MnistDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "# device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 100, bias=True), nn.ReLU(),\n",
    "    nn.Linear(100, 50, bias=True), nn.ReLU(),\n",
    "    nn.Linear(50, 10, bias=True), nn.Softmax(dim=-1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: [001/060] Acc=16.17% Loss=0.0717\n",
      "EPOCH: [002/060] Acc=32.87% Loss=0.0712\n",
      "EPOCH: [003/060] Acc=45.41% Loss=0.0616\n",
      "EPOCH: [004/060] Acc=68.18% Loss=0.0576\n",
      "EPOCH: [005/060] Acc=73.26% Loss=0.0518\n",
      "EPOCH: [006/060] Acc=74.36% Loss=0.0527\n",
      "EPOCH: [007/060] Acc=74.90% Loss=0.0521\n",
      "EPOCH: [008/060] Acc=75.22% Loss=0.0564\n",
      "EPOCH: [009/060] Acc=75.53% Loss=0.0593\n",
      "EPOCH: [010/060] Acc=75.72% Loss=0.0509\n",
      "EPOCH: [011/060] Acc=75.87% Loss=0.0536\n",
      "EPOCH: [012/060] Acc=75.97% Loss=0.0514\n",
      "EPOCH: [013/060] Acc=76.14% Loss=0.0520\n",
      "EPOCH: [014/060] Acc=78.35% Loss=0.0506\n",
      "EPOCH: [015/060] Acc=82.68% Loss=0.0487\n",
      "EPOCH: [016/060] Acc=83.71% Loss=0.0520\n",
      "EPOCH: [017/060] Acc=84.26% Loss=0.0491\n",
      "EPOCH: [018/060] Acc=84.58% Loss=0.0492\n",
      "EPOCH: [019/060] Acc=84.83% Loss=0.0491\n",
      "EPOCH: [020/060] Acc=85.02% Loss=0.0506\n",
      "EPOCH: [021/060] Acc=85.19% Loss=0.0502\n",
      "EPOCH: [022/060] Acc=85.32% Loss=0.0495\n",
      "EPOCH: [023/060] Acc=85.46% Loss=0.0495\n",
      "EPOCH: [024/060] Acc=85.59% Loss=0.0473\n",
      "EPOCH: [025/060] Acc=85.68% Loss=0.0497\n",
      "EPOCH: [026/060] Acc=85.81% Loss=0.0515\n",
      "EPOCH: [027/060] Acc=85.91% Loss=0.0505\n",
      "EPOCH: [028/060] Acc=86.01% Loss=0.0499\n",
      "EPOCH: [029/060] Acc=86.07% Loss=0.0477\n",
      "EPOCH: [030/060] Acc=86.15% Loss=0.0529\n",
      "EPOCH: [031/060] Acc=86.16% Loss=0.0497\n",
      "EPOCH: [032/060] Acc=86.26% Loss=0.0512\n",
      "EPOCH: [033/060] Acc=86.30% Loss=0.0512\n",
      "EPOCH: [034/060] Acc=86.41% Loss=0.0517\n",
      "EPOCH: [035/060] Acc=86.50% Loss=0.0515\n",
      "EPOCH: [036/060] Acc=86.55% Loss=0.0482\n",
      "EPOCH: [037/060] Acc=86.57% Loss=0.0523\n",
      "EPOCH: [038/060] Acc=86.67% Loss=0.0476\n",
      "EPOCH: [039/060] Acc=86.72% Loss=0.0458\n",
      "EPOCH: [040/060] Acc=86.75% Loss=0.0501\n",
      "EPOCH: [041/060] Acc=86.85% Loss=0.0512\n",
      "EPOCH: [042/060] Acc=86.86% Loss=0.0505\n",
      "EPOCH: [043/060] Acc=86.93% Loss=0.0489\n",
      "EPOCH: [044/060] Acc=86.96% Loss=0.0481\n",
      "EPOCH: [045/060] Acc=87.04% Loss=0.0528\n",
      "EPOCH: [046/060] Acc=87.08% Loss=0.0491\n",
      "EPOCH: [047/060] Acc=87.11% Loss=0.0517\n",
      "EPOCH: [048/060] Acc=87.17% Loss=0.0478\n",
      "EPOCH: [049/060] Acc=87.23% Loss=0.0526\n",
      "EPOCH: [050/060] Acc=87.27% Loss=0.0491\n",
      "EPOCH: [051/060] Acc=87.30% Loss=0.0501\n",
      "EPOCH: [052/060] Acc=87.33% Loss=0.0483\n",
      "EPOCH: [053/060] Acc=87.41% Loss=0.0512\n",
      "EPOCH: [054/060] Acc=87.47% Loss=0.0500\n",
      "EPOCH: [055/060] Acc=87.48% Loss=0.0524\n",
      "EPOCH: [056/060] Acc=87.53% Loss=0.0502\n",
      "EPOCH: [057/060] Acc=87.61% Loss=0.0489\n",
      "EPOCH: [058/060] Acc=87.65% Loss=0.0493\n",
      "EPOCH: [059/060] Acc=87.67% Loss=0.0476\n",
      "EPOCH: [060/060] Acc=87.73% Loss=0.0502\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 60\n",
    "n = 60000\n",
    "bsz = train_dataloader.batch_size\n",
    "for i in range(EPOCHS):\n",
    "    correct = 0\n",
    "    loss = 0\n",
    "    for batch_idx, sample in enumerate(train_dataloader):\n",
    "        x, y = sample[0].to(device), sample[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += torch.eq(torch.argmax(y_pred, dim=-1), y).sum().item()\n",
    "        loss += loss.item()\n",
    "    print(f'\\rEPOCH: [{i+1:03}/{EPOCHS:03}] Acc={correct/n:.2%} Loss={loss/bsz:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (5): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for sample in test_dataloader:\n",
    "    x, y = sample[0].to(device), sample[1].to(device)\n",
    "    y_pred = model(x)\n",
    "    correct += torch.eq(torch.argmax(y_pred, dim=-1), y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8719"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct.sum().item() / y_test.size(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
