{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import (\n",
    "    Dataset, RandomSampler, DataLoader)\n",
    "\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist(flatten=True, normalize=True, one_hot_label=False)\n",
    "\n",
    "x_train, y_train, x_test, y_test = (\n",
    "    torch.Tensor(d) for d in (x_train, y_train, x_test, y_test)\n",
    ")\n",
    "\n",
    "y_train = y_train.long()\n",
    "y_test = y_test.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MnistDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = MnistDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 100, bias=True), nn.ReLU(),\n",
    "    nn.Linear(100, 50, bias=True), nn.ReLU(),\n",
    "    nn.Linear(50, 10, bias=True), nn.Softmax(dim=-1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: [001 / 100] Acc=61.12% Loss=0.0517\n",
      "EPOCH: [002 / 100] Acc=86.38% Loss=0.0489\n",
      "EPOCH: [003 / 100] Acc=91.42% Loss=0.0499\n",
      "EPOCH: [004 / 100] Acc=92.74% Loss=0.0494\n",
      "EPOCH: [005 / 100] Acc=93.75% Loss=0.0481\n",
      "EPOCH: [006 / 100] Acc=94.59% Loss=0.0477\n",
      "EPOCH: [007 / 100] Acc=95.26% Loss=0.0461\n",
      "EPOCH: [008 / 100] Acc=95.91% Loss=0.0461\n",
      "EPOCH: [009 / 100] Acc=96.23% Loss=0.0468\n",
      "EPOCH: [010 / 100] Acc=96.61% Loss=0.0457\n",
      "EPOCH: [011 / 100] Acc=96.92% Loss=0.0471\n",
      "EPOCH: [012 / 100] Acc=97.25% Loss=0.0458\n",
      "EPOCH: [013 / 100] Acc=97.42% Loss=0.0467\n",
      "EPOCH: [014 / 100] Acc=97.60% Loss=0.0457\n",
      "EPOCH: [015 / 100] Acc=97.83% Loss=0.0474\n",
      "EPOCH: [016 / 100] Acc=97.97% Loss=0.0457\n",
      "EPOCH: [017 / 100] Acc=98.07% Loss=0.0458\n",
      "EPOCH: [018 / 100] Acc=98.16% Loss=0.0457\n",
      "EPOCH: [019 / 100] Acc=98.27% Loss=0.0466\n",
      "EPOCH: [020 / 100] Acc=98.35% Loss=0.0457\n",
      "EPOCH: [021 / 100] Acc=98.45% Loss=0.0459\n",
      "EPOCH: [022 / 100] Acc=98.54% Loss=0.0467\n",
      "EPOCH: [023 / 100] Acc=98.55% Loss=0.0457\n",
      "EPOCH: [024 / 100] Acc=98.62% Loss=0.0457\n",
      "EPOCH: [025 / 100] Acc=98.69% Loss=0.0467\n",
      "EPOCH: [026 / 100] Acc=98.73% Loss=0.0457\n",
      "EPOCH: [027 / 100] Acc=98.78% Loss=0.0457\n",
      "EPOCH: [028 / 100] Acc=98.82% Loss=0.0464\n",
      "EPOCH: [029 / 100] Acc=98.83% Loss=0.0467\n",
      "EPOCH: [030 / 100] Acc=98.89% Loss=0.0457\n",
      "EPOCH: [031 / 100] Acc=98.90% Loss=0.0457\n",
      "EPOCH: [032 / 100] Acc=98.94% Loss=0.0466\n",
      "EPOCH: [033 / 100] Acc=98.95% Loss=0.0457\n",
      "EPOCH: [034 / 100] Acc=98.98% Loss=0.0475\n",
      "EPOCH: [035 / 100] Acc=99.01% Loss=0.0457\n",
      "EPOCH: [036 / 100] Acc=99.03% Loss=0.0466\n",
      "EPOCH: [037 / 100] Acc=99.02% Loss=0.0467\n",
      "EPOCH: [038 / 100] Acc=99.05% Loss=0.0457\n",
      "EPOCH: [039 / 100] Acc=99.08% Loss=0.0476\n",
      "EPOCH: [040 / 100] Acc=99.08% Loss=0.0457\n",
      "EPOCH: [041 / 100] Acc=99.09% Loss=0.0457\n",
      "EPOCH: [042 / 100] Acc=99.09% Loss=0.0457\n",
      "EPOCH: [043 / 100] Acc=99.11% Loss=0.0457\n",
      "EPOCH: [044 / 100] Acc=99.12% Loss=0.0457\n",
      "EPOCH: [045 / 100] Acc=99.12% Loss=0.0457\n",
      "EPOCH: [046 / 100] Acc=99.14% Loss=0.0457\n",
      "EPOCH: [047 / 100] Acc=99.16% Loss=0.0457\n",
      "EPOCH: [048 / 100] Acc=99.17% Loss=0.0457\n",
      "EPOCH: [049 / 100] Acc=99.17% Loss=0.0457\n",
      "EPOCH: [050 / 100] Acc=99.18% Loss=0.0466\n",
      "EPOCH: [051 / 100] Acc=99.19% Loss=0.0466\n",
      "EPOCH: [052 / 100] Acc=99.19% Loss=0.0457\n",
      "EPOCH: [053 / 100] Acc=99.19% Loss=0.0457\n",
      "EPOCH: [054 / 100] Acc=99.19% Loss=0.0457\n",
      "EPOCH: [055 / 100] Acc=99.20% Loss=0.0457\n",
      "EPOCH: [056 / 100] Acc=99.20% Loss=0.0466\n",
      "EPOCH: [057 / 100] Acc=99.20% Loss=0.0457\n",
      "EPOCH: [058 / 100] Acc=99.22% Loss=0.0457\n",
      "EPOCH: [059 / 100] Acc=99.22% Loss=0.0457\n",
      "EPOCH: [060 / 100] Acc=99.23% Loss=0.0457\n",
      "EPOCH: [061 / 100] Acc=99.23% Loss=0.0457\n",
      "EPOCH: [062 / 100] Acc=99.23% Loss=0.0457\n",
      "EPOCH: [063 / 100] Acc=99.24% Loss=0.0457\n",
      "EPOCH: [064 / 100] Acc=99.25% Loss=0.0457\n",
      "EPOCH: [065 / 100] Acc=99.25% Loss=0.0476\n",
      "EPOCH: [066 / 100] Acc=99.26% Loss=0.0457\n",
      "EPOCH: [067 / 100] Acc=99.27% Loss=0.0457\n",
      "EPOCH: [068 / 100] Acc=99.27% Loss=0.0457\n",
      "EPOCH: [069 / 100] Acc=99.27% Loss=0.0466\n",
      "EPOCH: [070 / 100] Acc=99.26% Loss=0.0457\n",
      "EPOCH: [071 / 100] Acc=99.27% Loss=0.0457\n",
      "EPOCH: [072 / 100] Acc=99.27% Loss=0.0457\n",
      "EPOCH: [073 / 100] Acc=99.27% Loss=0.0457\n",
      "EPOCH: [074 / 100] Acc=99.27% Loss=0.0457\n",
      "EPOCH: [075 / 100] Acc=99.27% Loss=0.0457\n",
      "EPOCH: [076 / 100] Acc=99.27% Loss=0.0457\n",
      "EPOCH: [077 / 100] Acc=99.28% Loss=0.0457\n",
      "EPOCH: [078 / 100] Acc=99.27% Loss=0.0457\n",
      "EPOCH: [079 / 100] Acc=99.28% Loss=0.0466\n",
      "EPOCH: [080 / 100] Acc=99.28% Loss=0.0466\n",
      "EPOCH: [081 / 100] Acc=99.28% Loss=0.0466\n",
      "EPOCH: [082 / 100] Acc=99.28% Loss=0.0466\n",
      "EPOCH: [083 / 100] Acc=99.29% Loss=0.0466\n",
      "EPOCH: [084 / 100] Acc=99.29% Loss=0.0457\n",
      "EPOCH: [085 / 100] Acc=99.29% Loss=0.0466\n",
      "EPOCH: [086 / 100] Acc=99.29% Loss=0.0466\n",
      "EPOCH: [087 / 100] Acc=99.29% Loss=0.0457\n",
      "EPOCH: [088 / 100] Acc=99.29% Loss=0.0457\n",
      "EPOCH: [089 / 100] Acc=99.29% Loss=0.0457\n",
      "EPOCH: [090 / 100] Acc=99.29% Loss=0.0457\n",
      "EPOCH: [091 / 100] Acc=99.30% Loss=0.0457\n",
      "EPOCH: [092 / 100] Acc=99.30% Loss=0.0457\n",
      "EPOCH: [093 / 100] Acc=99.30% Loss=0.0457\n",
      "EPOCH: [094 / 100] Acc=99.30% Loss=0.0457\n",
      "EPOCH: [095 / 100] Acc=99.30% Loss=0.0457\n",
      "EPOCH: [096 / 100] Acc=99.31% Loss=0.0457\n",
      "EPOCH: [097 / 100] Acc=99.31% Loss=0.0457\n",
      "EPOCH: [098 / 100] Acc=99.31% Loss=0.0457\n",
      "EPOCH: [099 / 100] Acc=99.31% Loss=0.0466\n",
      "EPOCH: [100 / 100] Acc=99.31% Loss=0.0457\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "n = 60000\n",
    "bsz = train_dataloader.batch_size\n",
    "for i in range(EPOCHS):\n",
    "    correct = 0\n",
    "    loss = 0\n",
    "    for batch_idx, sample in enumerate(train_dataloader):\n",
    "        x, y = sample[0].to(device), sample[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += torch.eq(torch.argmax(y_pred, dim=-1), y).sum().item()\n",
    "        loss += loss.item()\n",
    "    print(f'\\rEPOCH: [{i+1:03} / {EPOCHS:03}] Acc={correct/n:.2%} Loss={loss/bsz:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (5): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for sample in test_dataloader:\n",
    "    x, y = sample[0].to(device), sample[1].to(device)\n",
    "    y_pred = model(x)\n",
    "    correct += torch.eq(torch.argmax(y_pred, dim=-1), y).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct / y_test.size(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
